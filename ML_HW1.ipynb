{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0uP6G6vkCSrEWtKf/zQz7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nouf7/ML/blob/main/ML_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1\n",
        "For this homework will be dealing with (CIFAR10) dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ygGEZPwFi_4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First Task:**\n",
        "\n",
        "1. Dataset Loading\n",
        "\n",
        "  1.1 : Start by loading the dataset (see the PyTorch documentation for guidance)\n",
        "\n",
        "  1.2 : Next, split the data into train, validation, and test splits.\n",
        "\n",
        "  1.3 : Normalize data to have mean 0 and standard deviation 1."
      ],
      "metadata": {
        "id": "8l4qmaJKji_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # Using torchvision, it’s extremely easy to load CIFAR10.\n",
        "import torchvision.transforms as transforms # transforms used for (data augmentation, normalization, resizing...etc)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "y32cx5ewkFOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_mean = 0.0\n",
        "cifar_std = 1.0\n",
        "# Define the transformations (including normalization)\n",
        "transform=torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((cifar_mean),(cifar_std))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYtSV1_bpbpD",
        "outputId": "f00c7700-e7d8-4bb9-870e-0e3b0a94b346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sizes of each split\n",
        "total_size = len(trainset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Use random_split to create the splits\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(trainset, [train_size, val_size, test_size])\n"
      ],
      "metadata": {
        "id": "kd64bp22uNDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_size, train_size, val_size, test_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-XiPT-xz55-",
        "outputId": "76cd5e0c-42b4-4665-a95a-b2a899292aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 35000 7500 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shuffle=True: When set to True, it shuffles the data at the beginning of each epoch (an epoch is one complete pass through the entire dataset). Shuffling is important during training to ensure that the model doesn't learn any order-related patterns in the data."
      ],
      "metadata": {
        "id": "AnHLQwdQ0-bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # You can adjust this as needed\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "Uwfn66GquUoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, I'm trying to check the mean and std, but it appears is not giving mean=0, std =1\n",
        "# ** NEED FIXING **\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vy1RWklpy-jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize variables to accumulate channel-wise means and stds\n",
        "channel_means = torch.zeros(3)\n",
        "channel_stds = torch.zeros(3)\n",
        "\n",
        "# Iterate through the dataset to calculate means and stds\n",
        "for images, _ in train_loader:\n",
        "    # Calculate mean and std for each channel\n",
        "    batch_means = torch.mean(images, dim=(0, 2, 3))\n",
        "    batch_stds = torch.std(images, dim=(0, 2, 3))\n",
        "\n",
        "    # Accumulate batch means and stds\n",
        "    channel_means += batch_means\n",
        "    channel_stds += batch_stds\n",
        "\n",
        "# Calculate the overall mean and std\n",
        "total_samples = len(train_loader.dataset)\n",
        "overall_mean = channel_means / total_samples\n",
        "overall_std = channel_stds / total_samples\n",
        "\n",
        "print(\"means:\", overall_mean)\n",
        "print(\"stds:\", overall_std)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o55LWl-wLzv",
        "outputId": "a74e6ddc-b5e0-4505-d761-8c46192ff45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "means: tensor([0.0077, 0.0075, 0.0070])\n",
            "stds: tensor([0.0039, 0.0038, 0.0041])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Second Task:**\n",
        "\n",
        "**2. Training Your Classifiers**\n",
        "  \n",
        "  2.1. MLP\n",
        "\n",
        "  Just as demonstrated in the discussion, you can Implement a classification model for CIFAR-10 using MLP layers. You should be able to achieve 50% accuracy with three linear layers with ReLU as the activation function."
      ],
      "metadata": {
        "id": "HDtPwrZv96k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP (Multi-Layer Perceptron) and CNN (Convolutional Neural Network) are both types of artificial neural networks, MLPs are versatile and used for a wide range of tasks but are less effective for grid-like data like images. CNNs are specialized for image-related tasks due to their ability to capture spatial hierarchies and local patterns efficiently. The choice between MLP and CNN depends on the nature of the data and the task you're trying to solve."
      ],
      "metadata": {
        "id": "HsDNgU5u9e4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU is used to make neural networks more expressive, efficient, and capable of learning complex patterns in data.\n"
      ],
      "metadata": {
        "id": "1MRETpTMAeBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP classifier\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # First fully connected layer\n",
        "        self.relu = nn.ReLU()  # ReLU activation function\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        x = self.relu(self.fc1(x))  # Apply ReLU to the first hidden layer\n",
        "        x = self.relu(self.fc2(x))  # Apply ReLU to the second hidden layer\n",
        "        x = self.fc3(x)  # Output layer\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8sb6IJW78gpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define hyperparameters for the MLP classifier\n",
        "input_size = 3 * 32 * 32  # CIFAR-10 images are 32x32 pixels with 3 channels (RGB)\n",
        "hidden_size = 256  # Number of neurons in each hidden layer (adjust as needed)\n",
        "num_classes = 10  # Number of classes in CIFAR-10\n",
        "learning_rate = 0.001  # Learning rate for optimizer\n",
        "num_epochs = 10  # Number of training epochs\n",
        "\n",
        "# Create the MLP classifier model\n",
        "mlp_model = MLPClassifier(input_size, hidden_size, num_classes)\n"
      ],
      "metadata": {
        "id": "sC3WbMTN8gsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.Adam(mlp_model.parameters(), lr=learning_rate)  # Adam optimizer\n"
      ],
      "metadata": {
        "id": "eludtyJF8gvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the MLP classifier\n",
        "for epoch in range(num_epochs):\n",
        "    mlp_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = mlp_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeLzfYJy8gy_",
        "outputId": "38cd50c0-c323-4598-f254-c8e8e5ba002d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.8413\n",
            "Epoch [2/10], Loss: 1.6109\n",
            "Epoch [3/10], Loss: 1.5992\n",
            "Epoch [4/10], Loss: 1.7406\n",
            "Epoch [5/10], Loss: 1.5669\n",
            "Epoch [6/10], Loss: 1.3715\n",
            "Epoch [7/10], Loss: 1.3103\n",
            "Epoch [8/10], Loss: 1.2739\n",
            "Epoch [9/10], Loss: 1.4488\n",
            "Epoch [10/10], Loss: 1.5876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "mlp_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = mlp_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF9yn9O18g2U",
        "outputId": "ffa5ab37-afc7-4034-8933-a834cf40f6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 46.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**2.2: CNN**\n",
        "\n",
        "  Try to use CNN layers in your classifier. You should be able to achieve 60% accuracy with three CNN layers.\n"
      ],
      "metadata": {
        "id": "diVJMnkrDHpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN classifier\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Adjusted input size to match the output of the last convolutional layer\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zvoP3ReY8g5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for the CNN classifier\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the CNN classifier model\n",
        "cnn_model = CNNClassifier(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "aewE89jj8g86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the CNN classifier\n",
        "for epoch in range(num_epochs):\n",
        "    cnn_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = cnn_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5waMUP_E4Xq",
        "outputId": "85740f53-40f2-474f-ac35-49e10d7cedc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.3640\n",
            "Epoch [2/10], Loss: 1.2443\n",
            "Epoch [3/10], Loss: 1.2754\n",
            "Epoch [4/10], Loss: 0.8831\n",
            "Epoch [5/10], Loss: 0.7941\n",
            "Epoch [6/10], Loss: 0.8885\n",
            "Epoch [7/10], Loss: 0.9736\n",
            "Epoch [8/10], Loss: 0.9205\n",
            "Epoch [9/10], Loss: 0.7680\n",
            "Epoch [10/10], Loss: 0.9016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "cnn_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = cnn_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiEbxS2tE4k5",
        "outputId": "855d1a36-1fb4-4749-b5bf-0342148b8513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 67.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "85fvON_ARTNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet, short for **\"Residual Network**,\" is a deep neural network architecture that was introduced in the paper titled \"Deep Residual Learning for Image Recognition\" by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, published in 2015. ResNet is a groundbreaking architecture known for its ability to train very deep neural networks effectively, overcoming the challenges of vanishing gradients and degradation that typically occur as networks become deeper."
      ],
      "metadata": {
        "id": "Lb0VBA_VROgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3. ResNet**\n",
        "\n",
        "  There is a widely used and powerful model architecture, ResNet. Fortunately, PyTorch has a built-in implementation of it. Check its document and try to use ResNet to train your classification model. You should be able to achieve 70% accuracy easily with ResNet-18.\n",
        "  ResNet is based on CNN and batch normalization layers. Batch normalization is implemented in PyTorch too (BatchNorm2D). Try to read the ResNet paper and implement ResNet by yourself. You can check the correctness of your implementation by comparing the performance of your implementation with the performance of the built-in one."
      ],
      "metadata": {
        "id": "XPlTK8eGHb2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet-18 classifier\n",
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "        # Load pre-trained ResNet-18 (omit final classification layer)\n",
        "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.resnet18.fc.in_features\n",
        "        # Add a new classification layer for CIFAR-10\n",
        "        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)\n"
      ],
      "metadata": {
        "id": "ewXeSK_tE4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for the ResNet-18 classifier\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the ResNet-18 classifier model\n",
        "resnet_model = ResNetClassifier(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "5M9tmjK0E4rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the ResNet-18 classifier\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = resnet_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXEfWQgkKBsM",
        "outputId": "39264427-41d1-4f98-a05e-913fd30d7c39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9175\n",
            "Epoch [2/10], Loss: 0.7376\n",
            "Epoch [3/10], Loss: 0.6429\n",
            "Epoch [4/10], Loss: 0.5350\n",
            "Epoch [5/10], Loss: 0.4381\n",
            "Epoch [6/10], Loss: 0.2442\n",
            "Epoch [7/10], Loss: 0.2519\n",
            "Epoch [8/10], Loss: 0.1349\n",
            "Epoch [9/10], Loss: 0.2436\n",
            "Epoch [10/10], Loss: 0.1108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "resnet_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = resnet_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy (ResNet-18): {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "id": "fSN_HQtzKGZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c9770c-bb12-4655-9129-777998dba148"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (ResNet-18): 78.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUE-2SkN7vtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tmw todo:\n",
        "\n",
        "- data augmentation\n",
        "- model analysis\n",
        "-questions/ observation"
      ],
      "metadata": {
        "id": "eWIYNcpUgRPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Data Augmentation**\n",
        "\n",
        "  Data augmentation is a technique people usually use when training a model. The main idea is to perturb the input and use the perturbed data along with the original data to train the model. This is as if we have more data to train the model. The library torchvision implemented many commonly used perturbations that can be used for data augmentation. Check the document and try to use some of them when training your classifier. Using RandomHorizontalFlip and RandomCrop, you should be able to achieve 80% accuracy easily with ResNet-18."
      ],
      "metadata": {
        "id": "RKMk1ggDKSzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop images with padding\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to mean=0 and std=1\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "W8QXZ8NyiGK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset with data augmentation for training\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "# Load CIFAR-10 dataset without data augmentation for testing\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-emv2rkxFne",
        "outputId": "7b1363ce-894b-4a55-f293-613f566161aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sizes of each split\n",
        "total_size = len(trainset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Use random_split to create the splits\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(trainset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 64  # You can adjust this as needed"
      ],
      "metadata": {
        "id": "bCEK-Y1VwxcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet-18 classifier\n",
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "        # Load pre-trained ResNet-18 (omit final classification layer)\n",
        "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.resnet18.fc.in_features\n",
        "        # Add a new classification layer for CIFAR-10\n",
        "        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)\n"
      ],
      "metadata": {
        "id": "llskSpqdwxpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for the ResNet-18 classifier\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the ResNet-18 classifier model\n",
        "resnet_model = ResNetClassifier(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLBc_K1VwxtZ",
        "outputId": "3c1a1583-b268-4b6c-dea1-82a92201ae6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the ResNet-18 classifier\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = resnet_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2XyximTwxxB",
        "outputId": "7ed559c6-b6aa-4eeb-a1fa-47eff8abf3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8028\n",
            "Epoch [2/10], Loss: 1.0316\n",
            "Epoch [3/10], Loss: 0.6643\n",
            "Epoch [4/10], Loss: 0.5434\n",
            "Epoch [5/10], Loss: 0.5404\n",
            "Epoch [6/10], Loss: 0.4818\n",
            "Epoch [7/10], Loss: 0.5812\n",
            "Epoch [8/10], Loss: 0.5789\n",
            "Epoch [9/10], Loss: 0.5349\n",
            "Epoch [10/10], Loss: 0.4171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "resnet_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = resnet_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy (ResNet-18): {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-nC6fvQ7x0d",
        "outputId": "e30e63f9-93b9-408e-e2e9-d0eaa22bf2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (ResNet-18): 78.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**4. Model Analysis**\n",
        "\n",
        "  Take a look at some examples of model predictions. When the model is incorrect, is it incorrect in reasonable ways? Look into how the model misclassifies images using e.g., a confusion matrix."
      ],
      "metadata": {
        "id": "YIS3yVS8Sgy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Questions/Observations:**\n",
        "1. Do you observe that the accuracy of the training set is usually greater than the accuracy of the testing set?\n",
        "2. Do you observe that the accuracy of the testing set is usually close to the accuracy of the validation set?\n",
        "3. In your experiment,do you observe your model overfit?Do you observe that ResNet-18 does not overfit as easily even though ResNet-18 has many parameters?"
      ],
      "metadata": {
        "id": "ODXXLM3MStz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Answers:\n",
        "\n",
        "1- Yes, it's a common observation that the accuracy of the training set tends to be higher than that of the testing set. This phenomenon, known as overfitting, occurs when a model becomes overly specialized in capturing the details and noise within the training data, making it struggle to generalize effectively to new, unseen data. Addressing overfitting through techniques like regularization, data augmentation, and monitoring validation metrics is crucial for achieving better generalization and improving testing set accuracy."
      ],
      "metadata": {
        "id": "C07k_i80Uj21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Based on the validation accuracy results for MLP, CNN, and ResNet, it does appear that the accuracy of the testing set is generally close to the accuracy of the validation set. While the specific numbers may vary (e.g., 50% for MLP, 67% for CNN, and 78% for ResNet), the testing set accuracy tends to be in the same ballpark as the validation set accuracy. This suggests that the models are reasonably good at generalizing their performance from the validation set to the testing set, which is a positive indication of model robustness and generalization."
      ],
      "metadata": {
        "id": "0NEetie8XG7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-ResNet-18 has a better capacity for generalization and is less prone to overfitting compared to MLP and CNN, despite its higher parameter count. This highlights the effectiveness of the architectural innovations in ResNet-18 for handling deep networks and complex datasets like CIFAR-10."
      ],
      "metadata": {
        "id": "zNAUgJZvXpuv"
      }
    }
  ]
}