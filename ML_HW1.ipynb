{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOX6hJi4wnY/5XTzkC1Y4x5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nouf7/ML/blob/main/ML_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1\n",
        "For this homework will be dealing with (CIFAR10) dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ygGEZPwFi_4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First Task:**\n",
        "\n",
        "1. Dataset Loading\n",
        "\n",
        "  1.1 : Start by loading the dataset (see the PyTorch documentation for guidance)\n",
        "\n",
        "  1.2 : Next, split the data into train, validation, and test splits.\n",
        "\n",
        "  1.3 : Normalize data to have mean 0 and standard deviation 1."
      ],
      "metadata": {
        "id": "8l4qmaJKji_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # Using torchvision, it’s extremely easy to load CIFAR10.\n",
        "import torchvision.transforms as transforms # transforms used for (data augmentation, normalization, resizing...etc)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "y32cx5ewkFOt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_mean = 0.0\n",
        "cifar_std = 1.0\n",
        "# Define the transformations (including normalization)\n",
        "transform=torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((cifar_mean),(cifar_std))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYtSV1_bpbpD",
        "outputId": "b5eb7849-0752-4b39-b178-f2c8d26b37ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43491548.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sizes of each split\n",
        "total_size = len(trainset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Use random_split to create the splits\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(trainset, [train_size, val_size, test_size])\n"
      ],
      "metadata": {
        "id": "kd64bp22uNDy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_size, train_size, val_size, test_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-XiPT-xz55-",
        "outputId": "76cd5e0c-42b4-4665-a95a-b2a899292aea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 35000 7500 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shuffle=True: When set to True, it shuffles the data at the beginning of each epoch (an epoch is one complete pass through the entire dataset). Shuffling is important during training to ensure that the model doesn't learn any order-related patterns in the data."
      ],
      "metadata": {
        "id": "AnHLQwdQ0-bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # You can adjust this as needed\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "Uwfn66GquUoR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, I'm trying to check the mean and std, but it appears is not giving mean=0, std =1\n",
        "# ** NEED FIXING **\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vy1RWklpy-jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize variables to accumulate channel-wise means and stds\n",
        "channel_means = torch.zeros(3)\n",
        "channel_stds = torch.zeros(3)\n",
        "\n",
        "# Iterate through the dataset to calculate means and stds\n",
        "for images, _ in train_loader:\n",
        "    # Calculate mean and std for each channel\n",
        "    batch_means = torch.mean(images, dim=(0, 2, 3))\n",
        "    batch_stds = torch.std(images, dim=(0, 2, 3))\n",
        "\n",
        "    # Accumulate batch means and stds\n",
        "    channel_means += batch_means\n",
        "    channel_stds += batch_stds\n",
        "\n",
        "# Calculate the overall mean and std\n",
        "total_samples = len(train_loader.dataset)\n",
        "overall_mean = channel_means / total_samples\n",
        "overall_std = channel_stds / total_samples\n",
        "\n",
        "print(\"means:\", overall_mean)\n",
        "print(\"stds:\", overall_std)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o55LWl-wLzv",
        "outputId": "3afd6f76-0700-4eef-ffbb-8b9431e16685"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "means: tensor([0.0077, 0.0075, 0.0070])\n",
            "stds: tensor([0.0038, 0.0038, 0.0041])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Second Task:**\n",
        "\n",
        "**2. Training Your Classifiers**\n",
        "  \n",
        "  2.1. MLP\n",
        "\n",
        "  Just as demonstrated in the discussion, you can Implement a classification model for CIFAR-10 using MLP layers. You should be able to achieve 50% accuracy with three linear layers with ReLU as the activation function."
      ],
      "metadata": {
        "id": "HDtPwrZv96k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP (Multi-Layer Perceptron) and CNN (Convolutional Neural Network) are both types of artificial neural networks, MLPs are versatile and used for a wide range of tasks but are less effective for grid-like data like images. CNNs are specialized for image-related tasks due to their ability to capture spatial hierarchies and local patterns efficiently. The choice between MLP and CNN depends on the nature of the data and the task you're trying to solve."
      ],
      "metadata": {
        "id": "HsDNgU5u9e4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU is used to make neural networks more expressive, efficient, and capable of learning complex patterns in data.\n"
      ],
      "metadata": {
        "id": "1MRETpTMAeBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP classifier\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # First fully connected layer\n",
        "        self.relu = nn.ReLU()  # ReLU activation function\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        x = self.relu(self.fc1(x))  # Apply ReLU to the first hidden layer\n",
        "        x = self.relu(self.fc2(x))  # Apply ReLU to the second hidden layer\n",
        "        x = self.fc3(x)  # Output layer\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8sb6IJW78gpO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define hyperparameters for the MLP classifier\n",
        "input_size = 3 * 32 * 32  # CIFAR-10 images are 32x32 pixels with 3 channels (RGB)\n",
        "hidden_size = 256  # Number of neurons in each hidden layer (adjust as needed)\n",
        "num_classes = 10  # Number of classes in CIFAR-10\n",
        "learning_rate = 0.001  # Learning rate for optimizer\n",
        "num_epochs = 10  # Number of training epochs\n",
        "\n",
        "# Create the MLP classifier model\n",
        "mlp_model = MLPClassifier(input_size, hidden_size, num_classes)\n"
      ],
      "metadata": {
        "id": "sC3WbMTN8gsh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.Adam(mlp_model.parameters(), lr=learning_rate)  # Adam optimizer\n"
      ],
      "metadata": {
        "id": "eludtyJF8gvn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the MLP classifier\n",
        "for epoch in range(num_epochs):\n",
        "    mlp_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = mlp_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeLzfYJy8gy_",
        "outputId": "cc1a2376-755e-43ee-be1d-48f2f0f5d725"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.9450\n",
            "Epoch [2/10], Loss: 1.7800\n",
            "Epoch [3/10], Loss: 1.4138\n",
            "Epoch [4/10], Loss: 1.8211\n",
            "Epoch [5/10], Loss: 1.3473\n",
            "Epoch [6/10], Loss: 1.5655\n",
            "Epoch [7/10], Loss: 1.6274\n",
            "Epoch [8/10], Loss: 1.7367\n",
            "Epoch [9/10], Loss: 1.3834\n",
            "Epoch [10/10], Loss: 1.2869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "mlp_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = mlp_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF9yn9O18g2U",
        "outputId": "99aaa801-f91c-46a0-822c-afaa63771c15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 48.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**2.2: CNN**\n",
        "\n",
        "  Try to use CNN layers in your classifier. You should be able to achieve 60% accuracy with three CNN layers.\n"
      ],
      "metadata": {
        "id": "diVJMnkrDHpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN classifier\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Adjusted input size to match the output of the last convolutional layer\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zvoP3ReY8g5B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for the CNN classifier\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the CNN classifier model\n",
        "cnn_model = CNNClassifier(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "aewE89jj8g86"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the CNN classifier\n",
        "for epoch in range(num_epochs):\n",
        "    cnn_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = cnn_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5waMUP_E4Xq",
        "outputId": "55c2d393-df9d-4389-a9ed-d8219e2871e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.2894\n",
            "Epoch [2/10], Loss: 1.0758\n",
            "Epoch [3/10], Loss: 0.8527\n",
            "Epoch [4/10], Loss: 0.9342\n",
            "Epoch [5/10], Loss: 0.6835\n",
            "Epoch [6/10], Loss: 0.5955\n",
            "Epoch [7/10], Loss: 0.6092\n",
            "Epoch [8/10], Loss: 0.5277\n",
            "Epoch [9/10], Loss: 0.6729\n",
            "Epoch [10/10], Loss: 0.3091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "cnn_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = cnn_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiEbxS2tE4k5",
        "outputId": "1c47b659-8567-4d22-c5f8-0010a8ae0082"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 69.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3. ResNet**\n",
        "\n",
        "  There is a widely used and powerful model architecture, ResNet. Fortunately, PyTorch has a built-in implementation of it. Check its document and try to use ResNet to train your classification model. You should be able to achieve 70% accuracy easily with ResNet-18.\n",
        "  ResNet is based on CNN and batch normalization layers. Batch normalization is implemented in PyTorch too (BatchNorm2D). Try to read the ResNet paper and implement ResNet by yourself. You can check the correctness of your implementation by comparing the performance of your implementation with the performance of the built-in one."
      ],
      "metadata": {
        "id": "XPlTK8eGHb2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet-18 classifier\n",
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "        # Load pre-trained ResNet-18 (omit final classification layer)\n",
        "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.resnet18.fc.in_features\n",
        "        # Add a new classification layer for CIFAR-10\n",
        "        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)\n"
      ],
      "metadata": {
        "id": "ewXeSK_tE4nv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for the ResNet-18 classifier\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the ResNet-18 classifier model\n",
        "resnet_model = ResNetClassifier(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M9tmjK0E4rB",
        "outputId": "1c428f71-3fb7-4882-afba-6c800dd88b5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 274MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the ResNet-18 classifier\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous batch\n",
        "        outputs = resnet_model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "    # Print training loss for this epoch\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXEfWQgkKBsM",
        "outputId": "452eedfe-651f-4086-9fac-56abbb1a7507"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8357\n",
            "Epoch [2/10], Loss: 0.6979\n",
            "Epoch [3/10], Loss: 0.6200\n",
            "Epoch [4/10], Loss: 0.6147\n",
            "Epoch [5/10], Loss: 0.4854\n",
            "Epoch [6/10], Loss: 0.1875\n",
            "Epoch [7/10], Loss: 0.1431\n",
            "Epoch [8/10], Loss: 0.1943\n",
            "Epoch [9/10], Loss: 0.2798\n",
            "Epoch [10/10], Loss: 0.3471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation set\n",
        "resnet_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = resnet_model(images)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "accuracy = 100 * correct / total  # Calculate accuracy\n",
        "print(f'Validation Accuracy (ResNet-18): {accuracy:.2f}%')  # Print validation accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSN_HQtzKGZU",
        "outputId": "9a4e9b2e-d895-412c-9677-8c6ad5f23da2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (ResNet-18): 77.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tmw todo:\n",
        "\n",
        "- data augmentation\n",
        "- model analysis\n",
        "-questions/ observation"
      ],
      "metadata": {
        "id": "eWIYNcpUgRPS"
      }
    }
  ]
}